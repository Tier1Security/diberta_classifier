{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tier1Security/roberta_classifier/blob/main/Anomaly_Evaluation_Suite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import RobertaTokenizer\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "from train_autoencoder import RobertaAutoencoder # Ensure this matches your training file\n",
        "\n",
        "# ==========================================\n",
        "# 1. Automated Merger Utility\n",
        "# ==========================================\n",
        "def merge_and_load_data(pattern=\"benign_baseline_*.csv\", output_file=\"benign_baseline.csv\"):\n",
        "    \"\"\"Merges all machine baselines into one master CSV.\"\"\"\n",
        "    files = glob.glob(pattern)\n",
        "    if not files:\n",
        "        print(f\"[!] No baseline files found for pattern: {pattern}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"[*] Merging {len(files)} machine baselines...\")\n",
        "    dfs = [pd.read_csv(f) for f in files]\n",
        "    master_df = pd.concat(dfs).drop_duplicates(subset=['command'])\n",
        "    master_df.to_csv(output_file, index=False)\n",
        "    print(f\"[+] Master Baseline: {len(master_df)} unique commands.\")\n",
        "    return master_df\n",
        "\n",
        "# ==========================================\n",
        "# 2. Evaluation & Metric Engine\n",
        "# ==========================================\n",
        "class AnomalyEvaluator:\n",
        "    def __init__(self, model_path, device=\"cuda\"):\n",
        "        self.device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
        "        checkpoint = torch.load(model_path, map_location=self.device)\n",
        "\n",
        "        self.model = RobertaAutoencoder().to(self.device)\n",
        "        self.model.load_state_dict(checkpoint['model_state'])\n",
        "        self.threshold = checkpoint['threshold']\n",
        "        self.tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "        self.model.eval()\n",
        "        print(f\"[+] Model loaded. Operational Threshold: {self.threshold:.6f}\")\n",
        "\n",
        "    def calculate_error(self, command):\n",
        "        \"\"\"Calculates reconstruction error for a single command.\"\"\"\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            command.lower(),\n",
        "            add_special_tokens=True,\n",
        "            max_length=128,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        ).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            emb, rec = self.model(encoding['input_ids'], encoding['attention_mask'])\n",
        "            error = torch.mean((emb - rec)**2).item()\n",
        "        return error\n",
        "\n",
        "    def run_stress_test(self, malicious_csv=\"mitre_atlas_raw.csv\"):\n",
        "        \"\"\"\n",
        "        Stress tests the engine against the entire MITRE Atlas.\n",
        "        Checks if malicious commands consistently exceed the benign threshold.\n",
        "        \"\"\"\n",
        "        print(f\"\\n[*] Starting Adversarial Stress Test against {malicious_csv}...\")\n",
        "        mal_data = pd.read_csv(malicious_csv)\n",
        "\n",
        "        results = []\n",
        "        for cmd in tqdm(mal_data['command']):\n",
        "            error = self.calculate_error(cmd)\n",
        "            results.append(error)\n",
        "\n",
        "        results = np.array(results)\n",
        "        success_rate = (results > self.threshold).mean() * 100\n",
        "\n",
        "        print(f\"\\n--- STRESS TEST RESULTS ---\")\n",
        "        print(f\"Total TTPs Tested: {len(results)}\")\n",
        "        print(f\"Average Malicious Error: {results.mean():.6f}\")\n",
        "        print(f\"Threshold Coverage: {success_rate:.2f}% (TTPs correctly flagged as Anomalous)\")\n",
        "        print(f\"Max Malicious Error: {results.max():.6f}\")\n",
        "        print(f\"Min Malicious Error: {results.min():.6f}\")\n",
        "\n",
        "        return success_rate\n",
        "\n",
        "    def evaluate_false_positives(self, benign_csv=\"benign_baseline.csv\", sample_size=1000):\n",
        "        \"\"\"Verifies False Positive Rate on a held-out benign sample.\"\"\"\n",
        "        print(f\"\\n[*] Evaluating False Positive Rate (FPR)...\")\n",
        "        benign_data = pd.read_csv(benign_csv).sample(sample_size)\n",
        "\n",
        "        errors = []\n",
        "        for cmd in tqdm(benign_data['command']):\n",
        "            errors.append(self.calculate_error(cmd))\n",
        "\n",
        "        errors = np.array(errors)\n",
        "        fpr = (errors > self.threshold).mean() * 100\n",
        "        print(f\"False Positive Rate: {fpr:.2f}%\")\n",
        "        return fpr\n",
        "\n",
        "# ==========================================\n",
        "# 3. Execution Script\n",
        "# ==========================================\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Merge the baselines from your collection machines\n",
        "    merge_and_load_data()\n",
        "\n",
        "    # 2. Initialize Evaluator (Assumes you've run train_autoencoder.py)\n",
        "    try:\n",
        "        evaluator = AnomalyEvaluator(\"anomaly_engine.pt\")\n",
        "\n",
        "        # 3. Evaluate FP Rate on Benign Data\n",
        "        evaluator.evaluate_false_positives()\n",
        "\n",
        "        # 4. Stress Test against the MITRE Catalogue (The Atlas)\n",
        "        evaluator.run_stress_test(\"mitre_atlas_raw.csv\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"[!] Missing anomaly_engine.pt or mitre_atlas_raw.csv. Train and Scrape first!\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "hnN_XHA-AhXM"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}