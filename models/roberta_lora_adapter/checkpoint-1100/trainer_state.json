{
  "best_global_step": 700,
  "best_metric": 1.0,
  "best_model_checkpoint": "models/roberta_lora_adapter/checkpoint-700",
  "epoch": 2.1653543307086616,
  "eval_steps": 100,
  "global_step": 1100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0984251968503937,
      "grad_norm": 6.254515647888184,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 1.3322,
      "step": 50
    },
    {
      "epoch": 0.1968503937007874,
      "grad_norm": 1.1685705184936523,
      "learning_rate": 3.960000000000001e-05,
      "loss": 0.4428,
      "step": 100
    },
    {
      "epoch": 0.1968503937007874,
      "eval_accuracy": 0.8858965272856131,
      "eval_f1": 0.8322966246576597,
      "eval_loss": 0.4691585302352905,
      "eval_runtime": 2.6406,
      "eval_samples_per_second": 1603.053,
      "eval_steps_per_second": 50.368,
      "step": 100
    },
    {
      "epoch": 0.2952755905511811,
      "grad_norm": 0.38748088479042053,
      "learning_rate": 5.96e-05,
      "loss": 0.0876,
      "step": 150
    },
    {
      "epoch": 0.3937007874015748,
      "grad_norm": 0.09344154596328735,
      "learning_rate": 7.960000000000001e-05,
      "loss": 0.0271,
      "step": 200
    },
    {
      "epoch": 0.3937007874015748,
      "eval_accuracy": 0.9709425939050319,
      "eval_f1": 0.9639177264974571,
      "eval_loss": 0.072125643491745,
      "eval_runtime": 2.6249,
      "eval_samples_per_second": 1612.64,
      "eval_steps_per_second": 50.669,
      "step": 200
    },
    {
      "epoch": 0.4921259842519685,
      "grad_norm": 0.06040586531162262,
      "learning_rate": 9.960000000000001e-05,
      "loss": 0.0119,
      "step": 250
    },
    {
      "epoch": 0.5905511811023622,
      "grad_norm": 0.029988925904035568,
      "learning_rate": 0.00011960000000000001,
      "loss": 0.0105,
      "step": 300
    },
    {
      "epoch": 0.5905511811023622,
      "eval_accuracy": 0.9910229151901725,
      "eval_f1": 0.9912932713242333,
      "eval_loss": 0.047048527747392654,
      "eval_runtime": 2.6207,
      "eval_samples_per_second": 1615.199,
      "eval_steps_per_second": 50.749,
      "step": 300
    },
    {
      "epoch": 0.6889763779527559,
      "grad_norm": 0.02074066363275051,
      "learning_rate": 0.0001396,
      "loss": 0.005,
      "step": 350
    },
    {
      "epoch": 0.7874015748031497,
      "grad_norm": 1.8138118982315063,
      "learning_rate": 0.0001596,
      "loss": 0.0034,
      "step": 400
    },
    {
      "epoch": 0.7874015748031497,
      "eval_accuracy": 0.9926765887077723,
      "eval_f1": 0.9926960431098233,
      "eval_loss": 0.03352929651737213,
      "eval_runtime": 2.6185,
      "eval_samples_per_second": 1616.551,
      "eval_steps_per_second": 50.792,
      "step": 400
    },
    {
      "epoch": 0.8858267716535433,
      "grad_norm": 0.6148672699928284,
      "learning_rate": 0.0001796,
      "loss": 0.0104,
      "step": 450
    },
    {
      "epoch": 0.984251968503937,
      "grad_norm": 0.02705848403275013,
      "learning_rate": 0.0001996,
      "loss": 0.0031,
      "step": 500
    },
    {
      "epoch": 0.984251968503937,
      "eval_accuracy": 0.9974013701866289,
      "eval_f1": 0.9973635675016209,
      "eval_loss": 0.008772751316428185,
      "eval_runtime": 2.6197,
      "eval_samples_per_second": 1615.834,
      "eval_steps_per_second": 50.769,
      "step": 500
    },
    {
      "epoch": 1.0826771653543308,
      "grad_norm": 0.004863944835960865,
      "learning_rate": 0.00019786026200873364,
      "loss": 0.003,
      "step": 550
    },
    {
      "epoch": 1.1811023622047245,
      "grad_norm": 0.003413741011172533,
      "learning_rate": 0.0001956768558951965,
      "loss": 0.001,
      "step": 600
    },
    {
      "epoch": 1.1811023622047245,
      "eval_accuracy": 0.9997637609260571,
      "eval_f1": 0.9997639652990753,
      "eval_loss": 0.00243631424382329,
      "eval_runtime": 2.625,
      "eval_samples_per_second": 1612.575,
      "eval_steps_per_second": 50.667,
      "step": 600
    },
    {
      "epoch": 1.279527559055118,
      "grad_norm": 0.002584032481536269,
      "learning_rate": 0.00019349344978165939,
      "loss": 0.0004,
      "step": 650
    },
    {
      "epoch": 1.3779527559055118,
      "grad_norm": 0.0024742763489484787,
      "learning_rate": 0.0001913100436681223,
      "loss": 0.0003,
      "step": 700
    },
    {
      "epoch": 1.3779527559055118,
      "eval_accuracy": 1.0,
      "eval_f1": 1.0,
      "eval_loss": 0.0011732785496860743,
      "eval_runtime": 2.6427,
      "eval_samples_per_second": 1601.741,
      "eval_steps_per_second": 50.326,
      "step": 700
    },
    {
      "epoch": 1.4763779527559056,
      "grad_norm": 0.004102523438632488,
      "learning_rate": 0.00018912663755458515,
      "loss": 0.0021,
      "step": 750
    },
    {
      "epoch": 1.574803149606299,
      "grad_norm": 0.09923163801431656,
      "learning_rate": 0.00018694323144104804,
      "loss": 0.0016,
      "step": 800
    },
    {
      "epoch": 1.574803149606299,
      "eval_accuracy": 0.9950389794472005,
      "eval_f1": 0.9948204045488558,
      "eval_loss": 0.019333548843860626,
      "eval_runtime": 2.6257,
      "eval_samples_per_second": 1612.158,
      "eval_steps_per_second": 50.654,
      "step": 800
    },
    {
      "epoch": 1.673228346456693,
      "grad_norm": 0.036749787628650665,
      "learning_rate": 0.00018475982532751092,
      "loss": 0.0006,
      "step": 850
    },
    {
      "epoch": 1.7716535433070866,
      "grad_norm": 0.0023114560171961784,
      "learning_rate": 0.0001825764192139738,
      "loss": 0.0002,
      "step": 900
    },
    {
      "epoch": 1.7716535433070866,
      "eval_accuracy": 1.0,
      "eval_f1": 1.0,
      "eval_loss": 0.00041544242412783206,
      "eval_runtime": 2.6257,
      "eval_samples_per_second": 1612.171,
      "eval_steps_per_second": 50.654,
      "step": 900
    },
    {
      "epoch": 1.8700787401574803,
      "grad_norm": 0.002032992197200656,
      "learning_rate": 0.0001803930131004367,
      "loss": 0.0002,
      "step": 950
    },
    {
      "epoch": 1.968503937007874,
      "grad_norm": 0.002110469387844205,
      "learning_rate": 0.00017820960698689957,
      "loss": 0.0002,
      "step": 1000
    },
    {
      "epoch": 1.968503937007874,
      "eval_accuracy": 1.0,
      "eval_f1": 1.0,
      "eval_loss": 0.0003306756552774459,
      "eval_runtime": 2.6302,
      "eval_samples_per_second": 1609.395,
      "eval_steps_per_second": 50.567,
      "step": 1000
    },
    {
      "epoch": 2.0669291338582676,
      "grad_norm": 0.0019860975444316864,
      "learning_rate": 0.00017602620087336246,
      "loss": 0.0002,
      "step": 1050
    },
    {
      "epoch": 2.1653543307086616,
      "grad_norm": 0.001970531651750207,
      "learning_rate": 0.00017384279475982534,
      "loss": 0.0001,
      "step": 1100
    },
    {
      "epoch": 2.1653543307086616,
      "eval_accuracy": 1.0,
      "eval_f1": 1.0,
      "eval_loss": 0.0002799979120027274,
      "eval_runtime": 2.6401,
      "eval_samples_per_second": 1603.367,
      "eval_steps_per_second": 50.377,
      "step": 1100
    }
  ],
  "logging_steps": 50,
  "max_steps": 5080,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 100,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 5,
        "early_stopping_threshold": 0.001
      },
      "attributes": {
        "early_stopping_patience_counter": 5
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1686032953045056.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
